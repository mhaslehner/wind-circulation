{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os, shutil                         # For issuing commands to the OS.\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import random\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "#from sklearn.metrics import confusion_matrixfrom sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "import urllib\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import MFDataset\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import requests\n",
    "from netCDF4 import Dataset\n",
    "import timeit\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# there are 37 pressure height levels\n",
    "# select pressure height and latitude levels\n",
    "pr0 =  15 #7 # 400mb\n",
    "pr1 =  25 # 15\n",
    "lat0 = 50 # 10 #150  # 5 # input in degrees N, must be more southward than lat1\n",
    "lat1 = 60 #60 #200# 60  # 90\n",
    "start = timeit.default_timer()\n",
    "fps = 3\n",
    "# directories and create lists of years in strings to be able to read in the files, which contain year in name. \n",
    "gafs = 'gafs01051979/gafs197901050003.nc' # 00/12 + 3 6 9 12\n",
    "ggap = 'ggap01051979/ggap197901050000-c.nc' # 00, 06, 12, 18\n",
    "dir = '/Volumes/Seagate Backup Plus Drive/meteo-badc/ggap/' # 1979-1993 (1995-2003)\n",
    "dir1 = '/Volumes/Seagate Backup Plus Drive/meteo-2/ggap/' # 1994-2018\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# 1979-1993\n",
    "year0 = 1979\n",
    "yrs = [(str(year0+i)+'/') for i in range(15)]\n",
    "yrs_ = [(year0+i) for i in range(15)]\n",
    "#print(yrs1)\n",
    "# 1994-2018, in combination with a different hard disk and path\n",
    "yrs1 = [(str(year0+i)+'/') for i in range(15,40)]\n",
    "yrs1_ = [(year0+i) for i in range(15,40)]\n",
    "#print(yrs1)\n",
    "# choose the hard disk (the data are distributed over 2 disks)\n",
    "di = 0\n",
    "if di == 0:\n",
    "    dir = dir\n",
    "    yrs = yrs\n",
    "    yrs_ = yrs_\n",
    "    mypath = [dir + ye for ye in yrs]\n",
    "else:\n",
    "    dir = dir1\n",
    "    yrs = yrs1\n",
    "    yrs_ = yrs1_\n",
    "    mypath = [dir1 + ye for ye in yrs1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants needed for arc calculation:\n",
    "R = 6371 * 1e3  # Earth radius, in m\n",
    "C = 2 * np.pi * R / 512.  # dr = 2*pi*R*cos(pi*phi/180) would be the whole arc\n",
    "\n",
    "# VO(t, p, latitude, longitude) (s**-1) \n",
    "# T(t, p, latitude, longitude)   (K)\n",
    "# W(t, p, latitude, longitude)   (Pa s**-1)\n",
    "# R(t, p, latitude, longitude)   (%)\n",
    "# CC(t, p, latitude, longitude)  (0 - 1)\n",
    "\n",
    "# ggap:\n",
    "# t\n",
    "# p = 37\n",
    "# latitude = 256\n",
    "# longitude = 512\n",
    "# p = 1000, 975, 950, 925, 900, 875, 850, 825, 800, 775, 750, 700, 650, 600,\n",
    "#     550, 500, 450, 400, 350, 300, 250, 225, 200, 175, 150, 125, 100, 70, 50,\n",
    "#     30, 20, 10, 7, 5, 3, 2, 1 ;\n",
    "\n",
    "# I calculated that 4-8 miles atm pressure height corresponds to 440 - 160 mb, so that we need to take the pressure levels\n",
    "# p = 400, 350, 300, 250, 200, 175, 150 (roughly), which means p[17:24]. (24 not included.. how is it in Python again?)\n",
    "# lat [ 89.462944    88.766945    88.06699     87.366035    86.6648  1.7543825    1.0526295    0.35087648  -0.35087648  \n",
    "# http://www.met.reading.ac.uk/~marc/it/snap/varList/eraVars/  --- list of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_per_day(dir,yr):   # yr is a single year \n",
    "    mypaths = dir + yr\n",
    "    files_in_year = [f for f in listdir(mypaths) if isfile(join(mypaths, f)) and name_is_good(f)]  \n",
    "    # lists files from path    \n",
    "    #dates2 = [dates[d] for d in range(len(dates)) if d % 5 == 0] # take only every 5th day, for plots\n",
    "    dates = np.unique(np.array([f[4:12] for f in files_in_year]))  #     \n",
    "    # dates: strings corresponding to indices 4:12 in the filenames ggapYYYYDDHHHH....nc\n",
    "    return dates,files_in_year # days in one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_files(mypath,files_for_day):\n",
    "    w_total = []\n",
    "    v_total = []\n",
    "    f_all = []\n",
    "    for file in files_for_day:  # daily values\n",
    "        # ---------------------------------------------------------------------------------------------------\n",
    "        # 1. Read in the (wind) data\n",
    "        # ----------------------------------------------------------------------------------------------------        \n",
    "        f = Dataset(mypath + file, 'r')\n",
    "        f_all.append(f)        \n",
    "        p = f.variables['p'][:]\n",
    "        lat = f.variables['latitude'][:]\n",
    "        lon = f.variables['longitude'][:]\n",
    "        # vort = f.variables['VO'] # vorticity [1/s]\n",
    "        v = f.variables['U']  # zonal wind (t,p,lat,lon)\n",
    "        w = f.variables['V']  # meridional wind\n",
    "        # time = f.variables['t'][:] # in these files this is only 1 value! (daily)\n",
    "        v_total.append(v)  # (t,p,lat,lon),(t,p,lat,lon),(t,p,lat,lon),...\n",
    "        w_total.append(w)\n",
    "    v_total = np.asarray(v_total)\n",
    "    v_total = np.sum(v_total, axis=0) / len(files_for_day)\n",
    "    w_total = np.asarray(w_total)\n",
    "    w_total = np.sum(w_total, axis=0) / len(files_for_day)\n",
    "    [f.close() for f in f_all]    \n",
    "    return v_total,w_total,lat,lon,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d [[[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]] (2, 3, 2)\n",
      "b [1 2 3] (3,)\n",
      "d*b [[[1.41421356 1.41421356]\n",
      "  [2.23606798 2.23606798]\n",
      "  [3.16227766 3.16227766]]\n",
      "\n",
      " [[1.41421356 1.41421356]\n",
      "  [2.23606798 2.23606798]\n",
      "  [3.16227766 3.16227766]]]\n"
     ]
    }
   ],
   "source": [
    "d = np.ones((2,3,2))#.reshape((2,3,2)) 3x2 -> 2x3\n",
    "a = np.ones((2,3,2))\n",
    "b = np.array([1,2,3])\n",
    "k = np.sqrt((d*b[:,None])**2+a**2)\n",
    "print('d',d,np.shape(d))\n",
    "print('b',b,np.shape(b))\n",
    "print('d*b',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "# I. Helping functions (circulation)\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n",
    "def lat_to_grid(latNorth,lat):\n",
    "        # this function makes the conversion from 'latitude North' to the corresponding grid coordinate of the field.\n",
    "        # latNorth is the latitude North counted from the equator, whereas the files start counting coordinates \n",
    "        # from the Nort pole\n",
    "        grid_length_in_degrees = 180/float(len(lat)) # nb of degrees per latitude grid coordinate \n",
    "        grid_coordinate = int(np.round((90-latNorth)/float(grid_length_in_degrees)))# given the latitude in degrees N, what is the \n",
    "        return grid_coordinate, grid_length_in_degrees  # coordinate index of the given nc.file?\n",
    "\n",
    "def Main(files_for_day,mypath,p0, p1, lat0, lat1,calculation_type):\n",
    "    \n",
    "        v_total,w_total,lat,lon,p = Read_files(mypath,files_for_day)\n",
    "        \n",
    "        l0, grid_length_in_degrees = lat_to_grid(lat0,lat) # 50N --> grid 57\n",
    "        l1, grid_length_in_degrees = lat_to_grid(lat1,lat) # 60N --> grid 43\n",
    "    \n",
    "        if calculation_type == 1:\n",
    "            # Calculate the circulation along a latitude circle around the globe: Sum_over_longitudes(v)*dl\n",
    "            cir, lat_selected = circulation(p0, p1, l0, l1, v_total, lat)\n",
    "            #if plo == True:\n",
    "            #    plot(timestep, p0, p1, l0, l1, cir, year_n)\n",
    "            # Calculate maximum circulation in given region for given day\n",
    "            maxi,pre_init,lat_init = max_circ(cir,p0,l0) # get the corresponding pressure height and latitude of the max circulation\n",
    "            (pre, latit) = maxi\n",
    "            # print('shape of circ',np.shape(cir),'cir[',pre_init, lat_init,']', cir[pre, latit], 'p', p[pre_init], ' (mb), lat', lat[lat_init],' (degrees) for file',file,'day ',timestep)\n",
    "            return cir, maxi, pre_init, lat_init\n",
    "        \n",
    "        if calculation_type == 2:\n",
    "            # for each time step, the 'circulation' is calculated as the sum over longitudes of maximal abs(v) over latitude and pressure height intervals.\n",
    "            # cir is a scalar in this case\n",
    "            cir = circulation2(l0, l1, p0,p1,v_total, w_total, lon, grid_length_in_degrees)\n",
    "            return cir\n",
    "\n",
    "def circulation2(l0,l1,p0,p1,v,w,lon, grid_length_in_degrees): # scalar value per time\n",
    "    # for a given pressure height, calculate the absolute value of the 2D velocity vectors for each longitude\n",
    "    # i = lat index \n",
    "    if l0 < l1:\n",
    "        print('There is something wrong with the latitude calculation',l0,'cannot be smaller than',l1)\n",
    "    max_v = []\n",
    "    max_lat = np.zeros(p1-p0)\n",
    "    v_ = v[0,p0:p1,l1:l0,0:len(lon)] # from l1=60N < l0= 50N to l0=50N  \n",
    "    w_ = w[0,p0:p1,l1:l0,0:len(lon)]\n",
    "    #v_ = np.flip(v_, axis=1)  # because later l0is larger than l1\n",
    "    #w_ = np.flip(w_, axis=1) \n",
    "  \n",
    "    grid_arr = np.array([i for i in range(l1,l0)]) # convert grid coordinates...\n",
    "    alpha_arr = np.array([(90 - grid_length_in_degrees*grid) for grid in grid_arr])# ..into degrees N\n",
    "    #print('grid ',grid_arr)\n",
    "    #print('alpha',alpha_arr)\n",
    "    #TEST\n",
    "    # grid  [43 44 45 46 47 48 49 50 51 52 53 54 55 56]\n",
    "    #alpha [59.765625 59.0625   58.359375 57.65625  56.953125 56.25     55.546875\n",
    "    # 54.84375  54.140625 53.4375   52.734375 52.03125  51.328125 50.625   ]\n",
    "    \n",
    "    \n",
    "    factor = np.array([(np.cos(alpha/180.))**2 for alpha in alpha_arr]) # ...before calculating the factor\n",
    "    factor = factor[:,None]    \n",
    "    velocity_norms = np.sqrt((v_**2)*factor + w_**2)\n",
    "    v_max_lat = np.max(velocity_norms, axis = 1) # take max along latitude-axis\n",
    "    v_max_p = np.max(v_max_lat, axis = 0)        # take max along pressure height axis\n",
    "    #plt.plot(range(len(lon)),v_max_p,linewidth=0.8)\n",
    "    #plt.savefig(\"circ_1.png\")\n",
    "    #plt.show()\n",
    "    v_max_sum = np.sum(v_max_p)                  # sum over longitudes \n",
    "    return v_max_sum\n",
    "    \n",
    "    # removed for loops -------------------------------------------------------------------   \n",
    "    #for each longitude, calculate the maximal abs value of velocity # for each longitude, calculate the maximal abs value of velocity            \n",
    "    #velocity_norms = [np.sqrt((v[0,p,i,j]**2)*(np.cos(i/180.))**2+w[0,p,i,j]**2) for i in range(l0,l1)]\n",
    "    #for j in range(len(lon)):     \n",
    "    #  for p in range(p0,p1):\n",
    "        # is an l1-l0 dim vector    \n",
    "    #    velocity_norms = [np.sqrt((v[0,p,i,j]**2)*(np.cos(i/180.))**2+w[0,p,i,j]**2) for i in range(l0,l1)] # for each longitude, calculate the maximal abs value of velocity                \n",
    "    #    max_lat[p-p0] = np.max(velocity_norms) # take maximum over latitudes            \n",
    "    #  max_p = np.max(max_lat[:])               # take max over pressure heights        \n",
    "    # max_v.append(max_p)  # get one value per longitude (the max abs value of the velocity over lats and pr heights, for given longitude)                       \n",
    "    # max_v = np.asarray(max_v)        \n",
    "    # v_max_sum = np.sum(max_v) # sum the absolute values, one value is returned, for a whole range of latitudes...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_ = np.zeros(10)\n",
    "#b_ = a_[2:5]\n",
    "#print(b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_circ(cir,p0,l0): # for circulation type 1, 'circulation', lost in this script\n",
    "    #print(np.shape(cir))\n",
    "    maxim = np.unravel_index(cir[:,:].argmax(), cir[:,:].shape)\n",
    "    (pre, latit) = maxim\n",
    "    pre_init = pre + p0\n",
    "    lat_init = latit + l0\n",
    "    return maxim,pre_init,lat_init\n",
    "\n",
    "def name_is_good(f):\n",
    "    if f[-3:] == '.nc':\n",
    "        return True\n",
    "    else:\n",
    "        False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "year  1979 mean circulation (m/s) 17725.657318271693\n",
      "year  1980 mean circulation (m/s) 16975.892376267737\n",
      "year  1981 mean circulation (m/s) 16710.439262484633\n",
      "year  1982 mean circulation (m/s) 17754.68723115047\n",
      "year  1983 mean circulation (m/s) 17030.43385112774\n",
      "year  1984 mean circulation (m/s) 16966.63582153195\n",
      "year  1985 mean circulation (m/s) 17353.680423396836\n",
      "year  1986 mean circulation (m/s) 17363.54084538414\n",
      "year  1987 mean circulation (m/s) 17338.185165244227\n",
      "year  1988 mean circulation (m/s) 17214.193366089494\n",
      "year  1989 mean circulation (m/s) 17808.871215594503\n",
      "year  1990 mean circulation (m/s) 18338.334983165303\n",
      "year  1991 mean circulation (m/s) 17375.034423874054\n",
      "year  1992 mean circulation (m/s) 17390.02107555528\n",
      "year  1993 mean circulation (m/s) 17014.305217933357\n"
     ]
    }
   ],
   "source": [
    "calculation_type = 2 # sum over absolute values of v\n",
    "calculate_circulation = True\n",
    "print('TEST')\n",
    "if calculate_circulation == True: \n",
    "  for k in range(len(yrs_)): # for each year\n",
    "  #for k in range(1):  \n",
    "    mypaths = dir + yrs[k]\n",
    "    #print(mypaths)\n",
    "    #d = dates[day] # has 365 inputs because of np.unique only takes sorted unique value...same day :-)\n",
    "    dates,files_in_year = files_per_day(dir,yrs[k]) # days in one year\n",
    "    #print('year ', yrs_[k])\n",
    "    timestep = 0    \n",
    "    file_name = 'Circ1_'+str(yrs_[k])+'.txt'\n",
    "    f = open(file_name,'w+')\n",
    "    circulat = np.zeros(len(dates))\n",
    "    cir_ = []\n",
    "    t = 0\n",
    "    for d in dates:  # all files, sorted according to the date, for a given year. Each file corresponds to a year\n",
    "        files_for_day = [f for f in files_in_year if f[4:12] == d]  # list of files corresponding to the given day d in the loop\n",
    "\n",
    "        # circulation version 1\n",
    "        #cir, max_cir, pre, latit = Main(files_for_day,mypaths,pr0, pr1, lat0, lat1,timestep,False)\n",
    "        #cir.append(cir) # ,pre.append(), latit\n",
    "        #f.write('%6.3f\\t %d\\t %d\\t \\n' % (cir[max_cir],pre,latit))  # \\n.. next line\n",
    "        #f.write(' '.join(str(x) for x in cir)+'\\n')\n",
    "        \n",
    "        # circulation version 2\n",
    "        circulat[timestep] = Main(files_for_day,mypaths,pr0, pr1, lat0, lat1,calculation_type)\n",
    "        #f.write(' '.join(str(x) for x in circulat)+'\\n')\n",
    "        f.write('%6.3f\\n' % circulat[timestep]) \n",
    "        #print(timestep, 'cir(t) = ', circulat[timestep],' (m/s)')\n",
    "        cir_.append(circulat[timestep])\n",
    "        timestep = timestep + 1\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    print('year ', yrs_[k], 'mean circulation (m/s)', np.mean(cir_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccgfilt_corr2\n",
    "%matplotlib inline\n",
    "#dir = '/Volumes/Seagate Backup Plus Drive/meteo-badc/ggap/' # 1979-1993 (1995-2003)\n",
    "#year_list = [(year0+i) for i in range(40)]\n",
    "\n",
    "#cutoff = 100# np.array([80,40])\n",
    "\n",
    "year0=1979\n",
    "\n",
    "year_list = [(year0+i) for i in range(40)]\n",
    "\n",
    "#print('analysis for years', year_list)\n",
    "\n",
    "total_cir = [np.loadtxt('Circ1_'+str(j)+'.txt') for j in year_list] #- result is [nparray(365,3) , nparray(366,3) , ...]\n",
    "#print('total circulation',np.shape(total_cir))\n",
    "#print(total_cir[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#dir = '/Volumes/Seagate Backup Plus Drive/meteo-badc/ggap/' # 1979-1993 (1995-2003)\n",
    "#year_list = [(year0+i) for i in range(40)]\n",
    "year0=1979\n",
    "year_list = [(year0+i) for i in range(40)]\n",
    "print('analysis for years', year_list)\n",
    "\n",
    "total_cir = [np.loadtxt('Circ1_'+str(j)+'.txt') for j in year_list] #- result is [nparray(365,3) , nparray(366,3) , ...]\n",
    "print(np.shape(total_cir))\n",
    "print('shape',[np.shape(x) for x in total_cir])\n",
    "print('concatenate circulation')\n",
    "total_cir = np.concatenate(total_cir,axis=0)\n",
    "print('shape of concatenated circ',np.shape(total_cir))\n",
    "\n",
    "time_len = [np.shape(x) for x in total_cir]\n",
    "print('time',len(time_len))\n",
    "\n",
    "#a=range(4)\n",
    "#b=[1+i for i in range(4)]\n",
    "#plt.figure()\n",
    "#plt.plot(a,b)\n",
    "\n",
    "print('plot')\n",
    "#print('why?')\n",
    "#print()\n",
    "plt.figure(figsize=(20,10)) \n",
    "plt.plot(range(len(time_len)),total_cir,linewidth=0.8)\n",
    "\n",
    "#plt.show();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(timestep,p0,p1,l0, l1,cir,year_n):\n",
    "    plt.switch_backend('agg')\n",
    "    cir_min = -1500\n",
    "    cir_max = 1500\n",
    "    levels = MaxNLocator(nbins=15).tick_values(cir[:, :].min(), cir[:, :].max())\n",
    "    # fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "    fig, ax1 = plt.subplots(nrows=1)\n",
    "    im = plt.imshow(np.transpose(cir[:, :]), extent=(p0 * 10, (p1 - 1) * 10, l1 - 1, l0),\n",
    "                    interpolation='nearest', cmap=cm.gist_rainbow)\n",
    "    # ax1.set_xticks(range(len(labels1)), [i for i in labels1])\n",
    "    # ax = fig.add_subplot(131)\n",
    "    # mesh = ax1.pcolormesh(data, cmap=cm)\n",
    "    im.set_clim(cir_min, cir_max)\n",
    "    fig.colorbar(im, shrink=0.6)\n",
    "    ax1.set_title('daily wind circulation (' + str(year_n) + '), day %03d ' % (timestep))\n",
    "    ax1.set_xlabel('pressure height')\n",
    "    ax1.set_ylabel('latitudes')\n",
    "    fig.tight_layout()\n",
    "    print('time step', timestep)\n",
    "    plt.savefig(\"_tmp%05d.png\" % timestep)\n",
    "\n",
    "def plot_final(p0,p1,l0,l1,cir,var,color):\n",
    "    fh = 5  # figheight\n",
    "    fw = 12.5  # figwidth\n",
    "    m = 6\n",
    "    plt.switch_backend('agg')\n",
    "    fig, ax1 = plt.subplots(nrows=1)\n",
    "    #adjustFigAspect(fig, aspect=.4)\n",
    "    fig.set_figheight(fh)\n",
    "    fig.set_figwidth(fw)\n",
    "    plt.plot((cir),'o',color,linewidth=1.1)\n",
    "    ax1.set_title('daily '+str(var)+' for region (p,lat) = (['+str(p0)+','+str(p1)+'],['+str(l0)+','+str(l1)+'])')\n",
    "    ax1.set_xlabel('year')\n",
    "    ax1.set_ylabel(''+str(var)+'')\n",
    "    fig.tight_layout()\n",
    "    plt.xticks(fontsize=m)\n",
    "    plt.yticks(fontsize=m)\n",
    "    ax1.legend(fontsize=m)\n",
    "    plt.savefig(''+str(var)+'1979-2018.png')\n",
    "\n",
    "def adjustFigAspect(fig, aspect=1):\n",
    "    '''\n",
    "    Adjust the subplot parameters so that the figure has the correct\n",
    "               aspect ratio.\n",
    "    '''\n",
    "    xsize, ysize = fig.get_size_inches()\n",
    "    minsize = min(xsize, ysize)\n",
    "    xlim = .4 * minsize / xsize\n",
    "    ylim = .4 * minsize / ysize\n",
    "    if aspect < 1:\n",
    "        ylim *= aspect\n",
    "    else:\n",
    "        xlim /= aspect\n",
    "    fig.subplots_adjust(left=.5 - xlim,\n",
    "                        right=.5 + xlim,\n",
    "                        bottom=.5 - ylim,\n",
    "                        top=.5 + ylim)\n",
    "#-----------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = False\n",
    "if movie == True:\n",
    " timestep = 0\n",
    " for d in dates:  # for those files corresponding to a same day, within each year, list all of them\n",
    "\n",
    "    print('plot figure for time step',timestep)\n",
    "    fps = 3                                         # nb of frames per second for the movie\n",
    "\n",
    "    cir_min = -1500\n",
    "    cir_max = 1500\n",
    "    movie_figures = True\n",
    "    if movie_figures == True:\n",
    "\n",
    "     plt.switch_backend('agg')\n",
    "     fig = plt.figure()\n",
    "     levels = MaxNLocator(nbins=15).tick_values(cir[:, :].min(), cir[:, :].max())\n",
    "     # pick the desired colormap, sensible levels, and define a normalization\n",
    "     # instance which takes data values and translates those into levels.\n",
    "     cmap = plt.get_cmap('PiYG')\n",
    "     norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "     # fig, (ax0, ax1) = plt.subplots(nrows=2)\n",
    "     fig, ax1 = plt.subplots(nrows=1)\n",
    "     pa = np.array([i for i in range(p0, p1)])  # array indices of pressure height\n",
    "     x = np.array([p[prs] for prs in pa])  # pressure at index, in mbar\n",
    "     y = lat  # latitude in degrees\n",
    "     im = plt.imshow(cir[:, :], extent=(x.min(), x.max(), y.max(), y.min()),\n",
    "                    interpolation='nearest', cmap=cm.gist_rainbow)\n",
    "     fig.colorbar(im, shrink=0.4)\n",
    "\n",
    "\n",
    "\n",
    "     #fig = plt.figure()\n",
    "     #ax = fig.add_subplot(131)\n",
    "     #mesh = ax1.pcolormesh(data, cmap=cm)\n",
    "     im.set_clim(cir_min, cir_max)\n",
    "\n",
    "     ax1.set_title('daily wind circulation (1979), day %03d ' %timestep)\n",
    "     fig.tight_layout()\n",
    "     print('time step',timestep)\n",
    "\n",
    "     plt.savefig(\"_tmp%05d.png\" % timestep)\n",
    "\n",
    "     timestep = timestep +1\n",
    "     #plt.clf()  # Clear the figure to make way for the next image.\n",
    "\n",
    "     if timestep == 364:\n",
    "        os.system(\"rm -f movie.mp4\")\n",
    "        os.system(\"./ffmpeg -r \" + str(fps) + \" -b 1800 -i _tmp%05d.png movie.mp4\")\n",
    "        os.system(\"rm _tmp*.png\")\n",
    "\n",
    "        exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
