{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os, shutil                         # For issuing commands to the OS.\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import random\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import bernoulli\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "#from sklearn.metrics import confusion_matrixfrom sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "import urllib\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import MFDataset\n",
    "import urllib.request\n",
    "from time import sleep\n",
    "import requests\n",
    "from netCDF4 import Dataset\n",
    "import timeit\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# VO(t, p, latitude, longitude) (s**-1) \n",
    "# T(t, p, latitude, longitude)   (K)\n",
    "# W(t, p, latitude, longitude)   (Pa s**-1)\n",
    "# R(t, p, latitude, longitude)   (%)\n",
    "# CC(t, p, latitude, longitude)  (0 - 1)\n",
    "\n",
    "# ggap:\n",
    "# t, latitude = 256, longitude = 512\n",
    "# p = 37\n",
    "# p = 1000, 975, 950, 925, 900, 875, 850, 825, 800, 775, 750, 700, 650, 600, 550, 500, 450, 400, 350,300, 250, \n",
    "#     225, 200, 175, 150, 125, 100, 70, 50,30, 20, 10, 7, 5, 3, 2, 1 ;\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# there are 37 pressure height levels\n",
    "# select pressure height and latitude levels\n",
    "pr0 =  0 #7 # 400mb\n",
    "pr1 =  25 # 15\n",
    "\n",
    "lat0 = 50 # 10 #150  # 5 # input in degrees N, must be more southward than lat1\n",
    "lat1 = 60 #60 #200# 60  # 90\n",
    "\n",
    "start = timeit.default_timer()\n",
    "fps = 3\n",
    "# directories and create lists of years in strings to be able to read in the files, which contain year in name. \n",
    "gafs = 'gafs01051979/gafs197901050003.nc' # 00/12 + 3 6 9 12\n",
    "ggap = 'ggap01051979/ggap197901050000-c.nc' # 00, 06, 12, 18\n",
    "dir = '/Volumes/Seagate Backup Plus Drive/meteo-badc/ggap/' # 1979-1993 (1995-2003)\n",
    "dir1 = '/Volumes/Seagate Backup Plus Drive/meteo-2/ggap/' # 1994-2018\n",
    "#-------------------------------------------------------------------------------------------------------------\n",
    "# 1979-1993\n",
    "year0 = 1979\n",
    "yrs = [(str(year0+i)+'/') for i in range(15)]\n",
    "yrs_ = [(year0+i) for i in range(15)]\n",
    "#print(yrs1)\n",
    "# 1994-2018, in combination with a different hard disk and path\n",
    "yrs1 = [(str(year0+i)+'/') for i in range(15,40)]\n",
    "yrs1_ = [(year0+i) for i in range(15,40)]\n",
    "#print(yrs1)\n",
    "# choose the hard disk (the data are distributed over 2 disks)\n",
    "di = 1\n",
    "if di == 0:\n",
    "    dir = dir\n",
    "    yrs = yrs\n",
    "    yrs_ = yrs_\n",
    "    mypath = [dir + ye for ye in yrs]\n",
    "else:\n",
    "    dir = dir1\n",
    "    yrs = yrs1\n",
    "    yrs_ = yrs1_\n",
    "    mypath = [dir1 + ye for ye in yrs1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function lists files from path    \n",
    "def name_is_good(f):\n",
    "    if f[-3:] == '.nc':\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "        \n",
    "def files_per_day(dir,yr):   # yr is a single year \n",
    "    mypaths = dir + yr\n",
    "    files_in_year = [f for f in listdir(mypaths) if isfile(join(mypaths, f)) and name_is_good(f)]     \n",
    "    #dates2 = [dates[d] for d in range(len(dates)) if d % 5 == 0] # take only every 5th day, for plots\n",
    "    #d = dates[day] # has 365 inputs because of np.unique only takes sorted unique value...same day :-)\n",
    "    dates = np.unique(np.array([f[4:12] for f in files_in_year])) # indices 4:12 in the filenames ggapYYYYDDHHHH..nc    \n",
    "    return dates,files_in_year # days in one year\n",
    "\n",
    "def Read_grid(mypath,files_for_day):\n",
    "    f_all = []\n",
    "    for file in files_for_day:  # daily values\n",
    "        f = Dataset(mypath + file, 'r')\n",
    "        #print(mypath + file)\n",
    "        f_all.append(f)          \n",
    "        p = f.variables['p'][:]\n",
    "        lat = f.variables['latitude'][:] # lat = [90,...0,...,-90]\n",
    "        #print(lat)\n",
    "        lon = f.variables['longitude'][:]\n",
    "    [f.close() for f in f_all]    \n",
    "    return lat,lon,p\n",
    "\n",
    "\n",
    "def Read_files(mypath,files_for_day,var):\n",
    "    total = []                            # (t,p,lat,lon)\n",
    "    f_all = []\n",
    "    for file in files_for_day:            # daily values\n",
    "        #print(mypath + file)\n",
    "        f = Dataset(mypath + file, 'r')\n",
    "        f_all.append(f)            \n",
    "        w = f.variables[var] \n",
    "        total.append(w)      \n",
    "    total = np.asarray(total)\n",
    "    total = np.sum(total, axis=0) / len(files_for_day) # calculate daily mean values\n",
    "    [f.close() for f in f_all]    \n",
    "    return total\n",
    "\n",
    "\n",
    "def lat_to_grid(latNorth,lat):\n",
    "        # latNorth is the latitude North counted from the equator, whereas the files start counting coordinates \n",
    "        # from the Nort pole\n",
    "        grid_length_in_degrees = 180/float(len(lat)) # nb of degrees per latitude grid coordinate \n",
    "        grid_coordinate = int((90-latNorth)/float(grid_length_in_degrees))# given the latitude in degrees N, what is the \n",
    "        return grid_coordinate                                     # coordinate index of the given nc.file?\n",
    "\n",
    "def Main(files_for_day,mypath,p0, p1, lat0, lat1):\n",
    "    \n",
    "        lat,lon,p = Read_grid(mypath,files_for_day)\n",
    "        T_tot = Read_files(mypath,files_for_day,'T')\n",
    "        T_tot = T_tot -273.15    # conversion to celsius\n",
    "        \n",
    "        l0 = lat_to_grid(lat0,lat) # 50N\n",
    "        l1 = lat_to_grid(lat1,lat) # 60N\n",
    "        #print(lat)\n",
    "        #print('lat0,1    ',lat0,lat1)\n",
    "        #print('gridlat0,1',l0,l1)\n",
    "        #print('test lat0,1',lat[l0],lat[l1])\n",
    "        T_tota = T_tot[0,p0:p1,l1:l0,0:len(lon)] \n",
    "        T_tota = np.flip(T_tota, axis=1) \n",
    "        T_total = np.mean(T_tota, axis = 2)        # mean temperature along longitudes\n",
    "        #\n",
    "        \n",
    "        #vo_total = Read_files(mypath,files_for_day,'VO')\n",
    "        #W_total = Read_files(mypath,files_for_day,'W')\n",
    "        #CC_total = Read_files(mypath,files_for_day,'CC')\n",
    "        \n",
    "        #v_ = v[0,p0:p1,l0:l1,0:len(lon)]\n",
    "        #w_ = w[0,p0:p1,l0:l1,0:len(lon)]\n",
    "        \n",
    "        return T_total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_t = Main(files_for_day,mypaths,pr0, pr1, lat0, lat1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lats:  50 60\n",
      "pr:  0 25\n",
      "year  1994\n",
      "year  1994 mean T (C) -21.195375\n",
      "--- 982.1127760410309 seconds ---\n",
      "year  1995\n",
      "year  1995 mean T (C) -20.959826\n",
      "--- 1973.497666835785 seconds ---\n",
      "year  1996\n",
      "year  1996 mean T (C) -21.396648\n",
      "--- 2965.8446350097656 seconds ---\n",
      "year  1997\n",
      "year  1997 mean T (C) -20.981768\n",
      "--- 3957.4904437065125 seconds ---\n",
      "year  1998\n",
      "year  1998 mean T (C) -20.844543\n",
      "--- 4950.238115787506 seconds ---\n",
      "year  1999\n",
      "year  1999 mean T (C) -20.88337\n",
      "--- 5935.653341054916 seconds ---\n",
      "year  2000\n",
      "year  2000 mean T (C) -21.090584\n",
      "--- 6907.562319993973 seconds ---\n",
      "year  2001\n",
      "year  2001 mean T (C) -20.85878\n",
      "--- 7862.906587839127 seconds ---\n",
      "year  2002\n",
      "year  2002 mean T (C) -20.876959\n",
      "--- 8824.290944099426 seconds ---\n",
      "year  2003\n",
      "year  2003 mean T (C) -20.641989\n",
      "--- 9785.895998954773 seconds ---\n",
      "year  2004\n",
      "year  2004 mean T (C) -20.730814\n",
      "--- 10758.357133865356 seconds ---\n",
      "year  2005\n",
      "year  2005 mean T (C) -20.509863\n",
      "--- 39017.33997178078 seconds ---\n",
      "year  2006\n",
      "year  2006 mean T (C) -20.64413\n",
      "--- 39982.91482877731 seconds ---\n",
      "year  2007\n",
      "year  2007 mean T (C) -20.6349\n",
      "--- 41007.992112874985 seconds ---\n",
      "year  2008\n",
      "year  2008 mean T (C) -20.80452\n",
      "--- 42078.67177295685 seconds ---\n",
      "year  2009\n",
      "year  2009 mean T (C) -21.03476\n",
      "--- 43036.87670993805 seconds ---\n",
      "year  2010\n",
      "year  2010 mean T (C) -20.617489\n",
      "--- 43995.844267845154 seconds ---\n",
      "year  2011\n",
      "year  2011 mean T (C) -20.968859\n",
      "--- 44954.37058496475 seconds ---\n",
      "year  2012\n",
      "year  2012 mean T (C) -20.733236\n",
      "--- 45912.41518688202 seconds ---\n",
      "year  2013\n",
      "year  2013 mean T (C) -20.61334\n",
      "--- 46872.517590761185 seconds ---\n",
      "year  2014\n",
      "year  2014 mean T (C) -20.77373\n",
      "--- 47829.85487484932 seconds ---\n",
      "year  2015\n",
      "year  2015 mean T (C) -20.54575\n",
      "--- 48788.94160580635 seconds ---\n",
      "year  2016\n",
      "year  2016 mean T (C) -20.573143\n",
      "--- 49749.95019984245 seconds ---\n",
      "year  2017\n",
      "year  2017 mean T (C) -20.569765\n",
      "--- 50719.67998600006 seconds ---\n",
      "year  2018\n",
      "year  2018 mean T (C) -21.17373\n",
      "--- 51283.62077188492 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#for k in range(len(yrs_)): # for each year\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "print('lats: ',lat0,lat1)\n",
    "print('pr: ',pr0,pr1)\n",
    "for k in range(len(yrs_)):  \n",
    "    mypaths = dir + yrs[k]\n",
    "    dates,files_in_year = files_per_day(dir,yrs[k]) # days in one year\n",
    "    print('year ', yrs_[k])\n",
    "    timestep = 0    \n",
    "    T_ = []           \n",
    "    file_name = 'Tno_'+str(yrs_[k])+'__.txt'\n",
    "    f = open(file_name,'w+')\n",
    "\n",
    "    for d in dates:  # all files, sorted according to the date, for a given year. Each file corresponds to a year        \n",
    "        files_for_day = [f for f in files_in_year if f[4:12] == d]  # list of files corresponding to the given day d in the loop       \n",
    "        lat,lon,p = Read_grid(mypaths,files_for_day)          \n",
    "        T_tot = Main(files_for_day,mypaths,pr0, pr1, lat0, lat1)\n",
    "        #print('T for day',d, T_tot[:,:])\n",
    "        for line in T_tot[:,:]:    \n",
    "            #print('T ',(T_tot[x,:] for x in line))\n",
    "            f.write(' '.join(str(x) for x in line)+'\\n')           \n",
    "        #f.write('# New slice\\n') \n",
    "        T_.append(T_tot[:,:])\n",
    "        timestep = timestep + 1       \n",
    "    f.close()\n",
    "    \n",
    "    print('year ', yrs_[k], 'mean T (C)', np.mean(T_))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-88bc2aed69a2>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-88bc2aed69a2>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    outfile.write('# Array shape: {0}\\n'.format(data.shape))\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    #with open(file_name,'w') as f: # (4,5,10)\n",
    "        #f.write('# Array shape: {0}\\n'.format(data.shape))\n",
    "        #for data_slice in f:\n",
    "        #   np.savetxt(f, data_slice, fmt='%-7.2f')\n",
    "        #   f.write('# New slice\\n')\n",
    "    \n",
    "\n",
    "data = np.arange(200).reshape((4,5,10))\n",
    "\n",
    "# Write the array to disk\n",
    "with open('test.txt', 'w') as outfile:\n",
    "    # I'm writing a header here just for the sake of readability\n",
    "    # Any line starting with \"#\" will be ignored by numpy.loadtxt\n",
    "    outfile.write('# Array shape: {0}\\n'.format(data.shape))\n",
    "\n",
    "    # Iterating through a ndimensional array produces slices along\n",
    "    # the last axis. This is equivalent to data[i,:,:] in this case\n",
    "    for data_slice in data:\n",
    "\n",
    "        # The formatting string indicates that I'm writing out\n",
    "        # the values in left-justified columns 7 characters in width\n",
    "        # with 2 decimal places.  \n",
    "        np.savetxt(outfile, data_slice, fmt='%-7.2f')\n",
    "\n",
    "        # Writing out a break to indicate different slices...\n",
    "        outfile.write('# New slice\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
